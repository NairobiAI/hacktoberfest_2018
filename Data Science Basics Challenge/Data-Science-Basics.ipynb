{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](nai-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure you are using a version of notebook greater than v.3. If you installed Anaconda with python 3 - this is likely to be fine. The next piece of code will check if you have the right version.\n",
    "2. The notebook has both some open test cases that you can use to test the functionality of your code - however it will be run on another set of test cases that you can't from which marks will be awarded. So passing all the tests in this notebook is not a guarantee that you have done things correctly - though its highly probable.\n",
    "3. When you are done create a zip file of your notebook and upload that\n",
    "4. For each cell where you see \"YOUR CODE HERE\" delete the return notImplemented statement when you write your code there - don't leave it in the notebook.\n",
    "5. Once you are done, you are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b957d40efa6af48bbed5ba469161b43",
     "grade": false,
     "grade_id": "cell-8458c96552072e77",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Data Science Primer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ffe09889708d30b51abb25f46e81b62f",
     "grade": false,
     "grade_id": "cell-1b32460e9740e59c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this exercise we will practise basic preparation techniques as concerns storage of data and models. This is a crucial process present in every data science project. As the project evolves, data may be manipulated and different model versions produced. These need to be tracked so as to maintain reproducibility, a crucial element of data science.\n",
    "\n",
    "There are many options for data and model storage in Python. In this exercise, we focus on elementary techniques requiring no more that the standard library. These ought to be applicable to even the smallest data science projects such as homeworks or course projects.\n",
    "\n",
    "This exercise is split into two parts, which should be completed in order. These mimic a typical workflow across a project's lifetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e7db56cdebf967b2f3ecfb4f1369cf2e",
     "grade": false,
     "grade_id": "cell-d12fc1cd39692c97",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load some common libraries used here\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2359840f4a37d5e2dfd7800d10823e57",
     "grade": false,
     "grade_id": "cell-ec27327248a2e452",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part I: Data Preparation and Exploration\n",
    "\n",
    "In this part, we will load a dataset provided with this exercise, prepare it by converting to the right types and finally plot it to explore the data.\n",
    "\n",
    "The dataset is stored in a CSV file with the following columns;\n",
    "[feature_1,feature_2,label] \n",
    "The values in each line are separated by a comma (',')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e962fde96982de8728106aca910d04f7",
     "grade": false,
     "grade_id": "cell-60830aa935bc0bc3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Using the libraries above write a function to read the dataset.\n",
    "\n",
    "The filename specified below. The final dataset should be a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_NAME = 'dataset_original.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "71f724bb4f4bd1d773f787fb6081e618",
     "grade": false,
     "grade_id": "load-implementation",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\" Load dataset from a CSV file.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    filename : str\n",
    "        The filename of the CSV.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data : array-like\n",
    "        Numpy array of the loaded data.\n",
    "        \n",
    "    Note\n",
    "    -----\n",
    "    Hints\n",
    "    1) Pay attention to the header (column names) when creating the array.\n",
    "    2) Pay attention to types read in (strings vs floats)\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(ORIGINAL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "954d0ea48786fc08b0fefb597d59136f",
     "grade": true,
     "grade_id": "load-test",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check your implementation against these basic tests\n",
    "assert len(data) == 1000\n",
    "assert data.shape == (1000, 3)\n",
    "### BEGIN HIDDEN_TESTS\n",
    "assert np.unique(data[:, 2]).tolist() == [0, 1]\n",
    "### END HIDDEN_TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we explore the data by plotting it. \n",
    "\n",
    "Please use the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(data):\n",
    "    \"\"\" Plot a simple dataset \"\"\"\n",
    "    plt.scatter(data[:, 0], data[:, 1], marker='o', c=data[:, 2], s=25, edgecolor='k')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2bd81f2c12f049ae2a0129b21d8a28e9",
     "grade": true,
     "grade_id": "run-plot",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the code to call the plot function above.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "739b6c8622858b008de9d87cf135c3b7",
     "grade": false,
     "grade_id": "cell-c1114683afbf746c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part II Post-processing Data\n",
    "\n",
    "In this part, we will modify the dataset. We make the assumption that there is some noise in the data define by the following rules:\n",
    "* Feature 1 should have values in the range $(-2, 2]$\n",
    "* Feature 2 should have values in the range $[-3, 1.5)$\n",
    "\n",
    "In practise, such rules are derived from domain knowledge from the area of interest. We will now filter the data and remove the 'noisy' samples (any sample which does not fall within ranges specified above). We also save the resulting dataset for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b3db8f288e59b363af96f81d8b665c9",
     "grade": false,
     "grade_id": "cell-84333d7e6f974dbd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Filter the data\n",
    "\n",
    "Implement a filter that uses the rules above to create a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0cf42d6f5df7a0e67df60cefb64c98ca",
     "grade": false,
     "grade_id": "filter-data",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def filter_data(data):\n",
    "    \"\"\" Filter dataset by removing samples which do not match the rules \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Dataset\n",
    "    Returns\n",
    "    -------\n",
    "    new_data : array-like\n",
    "        New dataset\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the filter call\n",
    "new_data = filter_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "913ff2cc64e9e8d71165653c559520ac",
     "grade": true,
     "grade_id": "filter-data-correct",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your implementation against the following.\n",
    "assert new_data.shape[0] == 804\n",
    "### BEGIN HIDDEN_TESTS\n",
    "assert (new_data[:, 0] > 2).all() == False\n",
    "assert (new_data[:, 0] < -2).all() == False\n",
    "assert (new_data[:, 1] < -3).all() == False\n",
    "assert (new_data[:, 1] > 1.5).all() == False\n",
    "### END HIDDEN_TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61c2aa823373e40cf3a23394e49a14da",
     "grade": false,
     "grade_id": "cell-a6894191ef418e63",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function to save the new dataset into a CSV file, with the specified name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5790db056e3e09777e38829f552548b7",
     "grade": false,
     "grade_id": "cell-e9ba203bc9ef2ebb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "NEW_FILE_NAME = 'dataset_clipped.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e72842fb70d95b3dfe81f0cafc775605",
     "grade": true,
     "grade_id": "cell-795ee4d62546b087",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41ecf7372b85d180e7911941b1cddfae",
     "grade": false,
     "grade_id": "cell-6153d68b8b630602",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run the function to save the dataset\n",
    "save_dataset(new_data, NEW_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e01836f2194a9e95d4a8e9a0be3bc057",
     "grade": false,
     "grade_id": "cell-0b9df4cae7a6b821",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We are done! Hurray. Let us summarized what we have accomplished.\n",
    "\n",
    "- Reading data from CSV files\n",
    "    - Preparing the data by converting to appropriate types, removing headers\n",
    "- Exploration by visualizing the data\n",
    "- Post processing the data by removing samples that do not match a specified criteria.\n",
    "- Saving the new dataset as a CSV file. \n",
    "\n",
    "We are now ready to take the new dataset and start doing further analysis and/or model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
